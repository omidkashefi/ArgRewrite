This article was interesting and mentioned points that I hadn't thought of before.  I do think that the self driving cars would help decrease the number of accidents that are caused by human error.  There are many heart breaking stories of death or serious injury resulting from persons under the influence getting behind the wheel.  One would think that the number of incidents would decrease with the popularity and affordability of Uber and Lyft.  It is much easier to get from point A to point B when you can simply order a driver on these apps.  Many people still choose to take the risk and drive themselves.  With self driving cars, we would not have to rely on intoxicated people to make the responsible decision to get a designated driver.  

The con I chose seems to be the most complicated logistically.  Who is blamed when something goes wrong?  If a child runs out in front of a car and the car cannot detect it quickly enough and does not stop, who is to blame?  I believe that many people would argue the side of what would happen if it was a human in control of the vehicle?  Would they have been able see the child out of their periphery and anticipate the child might run towards the road?  Perhaps the accident could have been prevented.  To add to this predicament, there will be people attempting to blame to manufacturer for visibility issues.  Other may argue that the driver should have been paying attention still.  What would the rules for that be?  Should the driver still be 100% focused on the road? If that is the case, then that would be conflicting with the pro that people under the influence could still use their cars.

From reading this article, I would have to say that, while self driving cars come with benefits,  I do not think we should work on replacing humans drivers with them solely.  I think that if the purpose is to make driving safer and minimize accidents, then drivers should also be 100% attentive to the road.  I think that driving and traffic conditions are too complicated to leave to just a robot.  There  are many last minute decisions that humans make that can actually save lives.  A self driving car would provide too much comfort to drivers and perhaps lead to them being less cautious.  A false sense of safety behind the wheel is very dangerous.  I think that even with self driving cars, drivers should be held responsible for any accidents (unless there is a true manufacturing error that causes the accident) because I believe that the responsibility still falls on the human to operate the vehicle safely.